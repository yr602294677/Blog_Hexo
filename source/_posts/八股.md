---
title: ## 八股
date: 2021-09-24 15:58:00
categories: "八股" 
tags: 八股
description: ## 面试问题准备


---





1. kafka

   * 为什么使用kafka
     * 缓冲和削峰：减少上游突发流量的冲击，将消息暂存在kafka中，让下游按照自己节奏慢慢处理，同时消息队列可以暂时堆积请求，即使消费者暂时挂掉，也不太影响业务正常运行
     * 解耦便于扩展：解耦重要流程，按照约定，传递消息即可
     * 异步通信：需要的时候再去处理发来的数据
   * kafka为什么快
     * kafka的消息是保存或缓存在磁盘上的
     * 写入数据快（写到硬盘中）
       * 顺序写入：（硬盘是机械结构，每次都会寻址并写入，寻址非常耗时）
         * 每个partition就是一个单独的文件，收到消息后将数据放到文件末尾
         * 消费者对每个topic都有一个单独的offset用于判断读取到哪个数据
         * offset由客户端保存
       * MMFile  Memory Mapped Files 内存映射文件
         * 充分利用了现代操作系统分页存储来利用内存提高I/O效率
         * 直接利用操作系统的Page来实现文件到物理内存的直接映射，完成映射之后你对物理内存的操作会被同步到硬盘上。
         * 但此操作不可靠，因为写到mmp的文件没有真正写到硬盘，只有程序主动flush时才会写到硬盘上
     * 读取数据快
       * 基于sendfile实现零拷贝
         * Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把文件发送给消费者，配合mmap作为文件读写方式，直接把它传给sendfile。减少了多次文件copy操作
         * 传统方式需要 数据-》硬盘-》内核缓冲区-》用户空间缓冲区-》内核空间socket缓冲区-》nic缓冲区-》网络发送到客户端
       * 批量压缩
         * Kafka允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩
     * 总结
       * 写数据时直接在单个partion文件的末尾添加，速度最快
       * 传递消息时将所有消息变成一个批量的文件，并进行合理压缩以减少网络io损耗
       * 读取消息时配合sendfile直接传递文件，减少copy次数

2. hashmap

   *   引入了红黑二叉树设计，当冲突的链表长度大于 8 时，会将链表转化成红黑二叉树结构，提高查询效率。 

   * 初始化时机、length、阈值、实际存储数量

     *   一般在第一次 put 的时候，调用 resize 方法进行 table 的初始化
     *   默认length为16,可以放下12个元素，

   * 扩容时机

     *   size>threshold时扩容，大小变为原来的2倍

   * Map map = new HashMap(1000); 当我们存入多少个元素时会触发map的扩容

     *   1024*0.75=768--》存入769元素时触发扩容

   * 如何扩容

     *   1.7
         *   扩大为原来两倍后，rehash重新放值
         *   头插法，可能导致死锁
     *   1.8
         *   扩大为原来两倍后，计算原key的hash与旧数组长度进行与操作，若结果为0，则放到原位置+原数组 长度

   * hashmap为啥是线程不安全的

     * hashmap的put方法用的是++i，由于"++i"操作并不是单单一行代码处理，它包含了“读取、添加、保存”的过程。而在多线程处理的情况下，线程A在执行“+1”的操作的时候如果没有保存而被切换走进行线程B的数据处理，最终就没有执行“+1”而出现数据不一致问题，因为我们拿到的数据不是保存操作后的，它就不具备原子性。

     * 可能出现数据覆盖的情况

       ```java
       // 如果没有hash碰撞则直接插入元素，若AB两个线程同时插入不同数据且两个数据hash值一样，此时同时进入以下代码
       //先执行的可能被后执行的覆盖
       if ((p = tab[i = (n - 1) & hash]) == null){
           tab[i] = newNode(hash, key, value, null);
        }
       ......
       ++this.modCount; //注意++this.modCount组合
       if (++this.size > this.threshold) {
             this.resize();
       }
       ```

     * 示例

       ```java
       public class test {
           public static void main(String[] args) {
               HashMapThread thread0 = new HashMapThread();
               HashMapThread thread1 = new HashMapThread();
               HashMapThread thread2 = new HashMapThread();
               thread0.start();
               thread1.start();
               thread2.start();
           }
       }
       
       class HashMapThread extends Thread {
           private static AtomicInteger ai = new AtomicInteger();
           private static Map<Integer, Integer> map = new HashMap<>();
       
           @Override
           public void run() {
               while (ai.get() < 10) {
                   map.put(ai.get(), ai.get());
                   ai.incrementAndGet();
                   System.out.println( map);
               }
           }
       }
       ```

       ```java
       {0=0, 2=2}
       {0=0, 2=2}
       {0=0, 2=2}
       {0=0, 4=4, 2=2, 3=3}
       {0=0, 2=2, 3=3}
       {0=0, 4=4, 5=5, 2=2, 6=6, 3=3}
       {0=0, 4=4, 5=5, 2=2, 3=3}
       {0=0, 4=4, 5=5, 2=2, 6=6, 3=3, 7=7, 8=8}
       {0=0, 4=4, 5=5, 2=2, 6=6, 3=3, 7=7}
       {8=8, 9=9, 2=2, 3=3, 5=5, 4=4, 6=6, 7=7}
       
       ```

   * concurrenthashmap是怎么实现线程安全的？

     * hashtable是直接在get和put上加synchronized关键字，在高并发情况下影响效率
     
     *  共享变量的存储和读取全部通过volatile或CAS的方式来保证并发安全 ，同时put时 只锁定当前链表或红黑二叉树的首节点，只要节点 hash 不冲突，就不会产生并发 
     
       *  **cas **：compare and swap 
     
         *  CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 
     
           ```java
           if(valueOf(V)==A){
           	A==B;
           }
           ```
     
           
     
         * 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。
     
         * CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。
     
     * （1.7） 分段部分数据锁定 ，一个concurrenthashmap由多个segment组成，每个segment'有单独的锁，通过Hash函数将即将要put 的元素均匀的放到所需要的Segment 段中，然后调用Segment的put （ **加锁**）方法进行添加数据 
     
   * concurrenthashmap的key和value不允许为null
     
     * 无法确定是value存的就是null还是说key不存在，可能引起歧义，但hashmap非并发编程中可以进一步调用containsKey来判断

* 平衡二叉树

3. get、post区别
   * get是幂等的，一般用于获取资源；post是非幂等的，一般用于创建或更新资源
   * get不安全，因为数据放在url中，post则放在requestbody中
   * post在后退或者刷新时会提示重新提交数据，get无反应
   * get提交数据最长为2048字节（浏览器或服务器添加的此限制）
   * get是head和data一起发，服务器返回200；post是head发了，服务器返回100，再发data
   
4. 自我介绍

   老师好，我叫杨锐，2018年毕业于山东大学信息与计算科学专业。目前是在济南浪潮集团智慧粮食事业部从事粮食相关的系统开发，平时工作主要是负责为国家粮食局开发系统，帮助他们实现对下属各级粮库的监管清查，由于感觉现在的工作能够较为轻松地完成，因此打算到北京找找工作机会提升自己的能力，非常感谢今天抖音给我这个面试的机会。

5. mysql

   * innoDB引擎
     * 支持行级锁和表级锁，并发性能更高，默认行级锁
     * 支持事务，具有提交(commit)和回滚(rollback)事务的能力
     * 支持外键（酌情使用）
     * 支持数据库异常崩溃后的安全回复，依赖于redo log
     * 支持mvcc
   * 事务
     * 保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。要么全部成功，要么全部不成功。
     * 四大特性 ACID
       * **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
       * **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
       * **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
       * **持久性**（`Durability`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
   * 支持事务的原理
     * **redo log** 日志保证持久性
     * **undo log** 保证原子性
     * 锁机制和**mvcc**保证隔离性（默认为repeatable-read）
     * 持久性、原子性、隔离性一起保证一致性
   * 日志
     * binlog
       * 不分引擎，由mysql自行记录
       * 用于记录数据库的写入性信息（不包括查询），二进制格式保存在磁盘中
       * 追加方式写入，通过max_binlog_size设置每个文件的大小
       * 使用场景
         * 主从复制：master端将binlog发送给slave端，slave端重放binlog实现主从一致
         * 数据恢复：使用mysqlbinlog工具来恢复数据
     * redo log
       * 只记录事务对数据页做了哪些修改
       * 包括内存上的redo log buffer和磁盘redo log file 两部分
       * mysql每执行一条dml语句，就将记录先写到redo log buffer 里，后续一次性将多个logbuffer传到操作系统的内核空间的缓冲区odsbuffer，再通过系统调用fsync()将其刷到磁盘里
       * innodb_flush_log_at_trx_commit参数
         * 0：每秒将logbuffer-》 osbuffer-》logfile
         * 1：每次提交都logbuffer-》 osbuffer-》logfile，频繁io，效率低，但不会丢失数据
         * 2：每次提交都logbuffer-》 osbuffer；每秒 osbuffer-》logfile
       * 大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志
       * 需要binlog和redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。
     * undo log
       * 记录数据的逻辑变化，执行一条insert对应一条undo log中的delete语句，保证发生错误时，能够正确恢复状态。
     * 具体场景
       * 假如某个时刻数据库崩溃，在崩溃之前有事务A和事务B在执行，事务A已经提交，而事务B还未提交。当数据库重启进行 crash-recovery 时，就会通过Redo log将已经提交事务的更改写到数据文件，而还没有提交的就通过Undo log进行roll back。
     * 隔离级别（隔离效果越来越强，但性能越来越差）
       * **读未提交（READ UNCOMMITTED）**
         * 会读到另一个事务的未提交的数据，产生脏读问题
       * **读提交 （READ COMMITTED）**
         * 解决了脏读的，出现了不可重复读，即在一个事务任意时刻读到的数据可能不一样，可能会受到其它事务对数据修改提交后的影响，一般是对于update的操作。
       * **可重复读 （REPEATABLE READ）**
         * 带来了幻读的问题，幻读一般是针对inser操作。 	
         * 幻读：新增了一条数据后，最开始select的全部行发生了变化
       * **串行化 （SERIALIZABLE）**
   * B+树
     * 数据都存在叶子节点，遍历一遍就可以获取所有数据
   
6. 计算机网络

   * tcp协议

     * 分为应用层、运输测层、网际层、网络接口层
     * 应用层：定义主机正在运行程序间通信和交互的规则，不同应用如域名解析DNS、发送电子邮件SMTP、万维网http都需要使用不同的协议。
       * 应用层协议会使用到运输层协议
     * 运输层：两台主机之间的通信协议，主要分tcp、udp两种协议
       * tcp：面向连接、数据可靠
       * udp：无连接、数据量大、不可靠
     *  网络层：选择合适的网间路由和几点，发送运输层产生的用户数据和报文

   * TCP的三次握手与四次挥手

     * 如果已经建立了连接，但是客户端突然出现故障了怎么办
       * 服务器收到客户端请求后会设置一个等待时长H。若H时间内没收到客户端信息，会隔75s发送一个探测报文段，十个报文段都没有回应则关闭链接。

   * http和https区别

     * https是包了一层ssl的http，https=http--》ssl--》tcp
     * http端口80 https端口443
     * https由于需要加密解密，开销更大

   * http

     * request

     ```http
     <!--请求行--> 
     POST /dtjg/service/mxzc/getMxsrList?id=7570b6a843814279ad27738a3af5bc24 HTTP/1.1
     <!--请求头-->
     Host: 10.110.86.204:8080
     Connection: keep-alive
     Content-Length: 39
     Accept: application/json, text/javascript, */*; q=0.01
     X-Requested-With: XMLHttpRequest
     User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36 Edg/94.0.992.31
     Content-Type: application/json
     Origin: http://10.110.86.204:8080
     Referer: http://10.110.86.204:8080/dtjg/service/mxzc/showMxzcDetailPage?id=7570b6a843814279ad27738a3af5bc24
     Accept-Encoding: gzip, deflate
     Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6
     Cookie: jsessionid=fwAAAR-QYVPUGvz5tSeiYUoItQ_al_PTNE4A; jsessionid=fwAAASI6YVPUGs4Ffct1M0CstxOtG3QH1PwA
     <!--请求体-->
     id: 7570b6a843814279ad27738a3af5bc24
     ```

     

     * reponse

     ```http
     <!--状态行--> 
     HTTP/1.1 200 OK
     <!--响应头--> 
     Access-Control-Allow-Origin: http://10.110.86.204
     Access-Control-Allow-Credentials: true
     Content-Type: application/json;charset=UTF-8
     Date: Wed, 29 Sep 2021 02:49:08 GMT
     Transfer-Encoding: chunked
     Connection: keep-alive
     <!--响应体--> 
     {"pttgcs":"cflx","mxdycs":"cflx","id":"c4eb27bd214f48bb8d0c260a95408ff3","zbid":"7570b6a843814279ad27738a3af5bc24"}
     ```

     

